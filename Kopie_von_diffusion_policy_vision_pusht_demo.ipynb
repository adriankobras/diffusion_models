{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17495902022d4ad5b24cad740cf9c1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7586ebd7358d48cdbbee37593797804e",
              "IPY_MODEL_6c9f8c7f692f45318ad29bcb65cd6344",
              "IPY_MODEL_fdd0f37e33f742d4b790b0d64697fe83"
            ],
            "layout": "IPY_MODEL_8888d54e6f454a68bc26b45e7824f6e7"
          }
        },
        "7586ebd7358d48cdbbee37593797804e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e7d0314724e43c48ab494edd105eb4d",
            "placeholder": "​",
            "style": "IPY_MODEL_41d3a0c27922408b87d5b6599a4281fb",
            "value": "Epoch:   0%"
          }
        },
        "6c9f8c7f692f45318ad29bcb65cd6344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3587c826181f4578b9df3c5ba7425a3b",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7975925b464d4c6b8f78837da82a2c8f",
            "value": 0
          }
        },
        "fdd0f37e33f742d4b790b0d64697fe83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f82530285508473aaa7e0b48c8c26792",
            "placeholder": "​",
            "style": "IPY_MODEL_967069f2a7fc4b419d9ed15e787bd3ea",
            "value": " 0/100 [00:06&lt;?, ?it/s]"
          }
        },
        "8888d54e6f454a68bc26b45e7824f6e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e7d0314724e43c48ab494edd105eb4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41d3a0c27922408b87d5b6599a4281fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3587c826181f4578b9df3c5ba7425a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7975925b464d4c6b8f78837da82a2c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f82530285508473aaa7e0b48c8c26792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "967069f2a7fc4b419d9ed15e787bd3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af12ac7fcc71474ca44d11f27f3023c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_195a12c694594acc89e4840a44574087",
              "IPY_MODEL_95cf8565184e4601948ea7ef142bda96",
              "IPY_MODEL_abed40b66be14ab198ee304940bc438f"
            ],
            "layout": "IPY_MODEL_3776e3970e244e518d365cdde07358fc"
          }
        },
        "195a12c694594acc89e4840a44574087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704ae26d31cc43d483d5459fad17778b",
            "placeholder": "​",
            "style": "IPY_MODEL_702901ec086240bcaf88e4c62939357a",
            "value": "Batch:   1%"
          }
        },
        "95cf8565184e4601948ea7ef142bda96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30f2aa65d71844fab3371983c6c9f420",
            "max": 379,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d057f930be1240129112568a4d0b0be3",
            "value": 2
          }
        },
        "abed40b66be14ab198ee304940bc438f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88df1f95725048f8ad5b8366a7dd0055",
            "placeholder": "​",
            "style": "IPY_MODEL_8b0a31db42b94bdda58762dbb4b1d841",
            "value": " 2/379 [00:06&lt;16:55,  2.69s/it, loss=1.14]"
          }
        },
        "3776e3970e244e518d365cdde07358fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "704ae26d31cc43d483d5459fad17778b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "702901ec086240bcaf88e4c62939357a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30f2aa65d71844fab3371983c6c9f420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d057f930be1240129112568a4d0b0be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88df1f95725048f8ad5b8366a7dd0055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0a31db42b94bdda58762dbb4b1d841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ea302ecb58e4ee793a18ece76a6f6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab6362e541434aa292e31fc00c5c379c",
              "IPY_MODEL_d97efc62e6e54ff4ba4b5173d10b1601",
              "IPY_MODEL_2e8b2a80b0eb470c838e9d6f66271827"
            ],
            "layout": "IPY_MODEL_6144b327367b4c7f98c9678fb036965d"
          }
        },
        "ab6362e541434aa292e31fc00c5c379c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ca91d495d62414daed2b4e90b6ec949",
            "placeholder": "​",
            "style": "IPY_MODEL_fec07e1832e849cfb7d444055a6a11c5",
            "value": ""
          }
        },
        "d97efc62e6e54ff4ba4b5173d10b1601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae6eb79f11e49358cdaf4b8c8d6c88f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97146c21e3d249b8977f1717cb31ac04",
            "value": 0
          }
        },
        "2e8b2a80b0eb470c838e9d6f66271827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea552842de2940bfa7c5f48870ec01af",
            "placeholder": "​",
            "style": "IPY_MODEL_a27fa8eb71d9418397e07ba0f420a32e",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "6144b327367b4c7f98c9678fb036965d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca91d495d62414daed2b4e90b6ec949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec07e1832e849cfb7d444055a6a11c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ae6eb79f11e49358cdaf4b8c8d6c88f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "97146c21e3d249b8977f1717cb31ac04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea552842de2940bfa7c5f48870ec01af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a27fa8eb71d9418397e07ba0f420a32e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f38f444596eb4d30970dc3b7b623feae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95025eff74fc41bba34c06ead454c179",
              "IPY_MODEL_995fc6fe002b427f953dc4f6bbe3b76e",
              "IPY_MODEL_65b24fe04a444e4185e6cd24b03b4ff9"
            ],
            "layout": "IPY_MODEL_a776f50ea9df4e2bb5e311ab6b9028df"
          }
        },
        "95025eff74fc41bba34c06ead454c179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71fff78494694f4f9b4565e74362c116",
            "placeholder": "​",
            "style": "IPY_MODEL_2be82f21ebf54be4bde9a0d5d64e100f",
            "value": "Eval PushTImageEnv: "
          }
        },
        "995fc6fe002b427f953dc4f6bbe3b76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6781cbfdcd1f45bb8f7e016395ebcde1",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d25fb1f7c0ae4c7d95ba796febfe6873",
            "value": 200
          }
        },
        "65b24fe04a444e4185e6cd24b03b4ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70250a5da924ca2b5a54b9c177c3082",
            "placeholder": "​",
            "style": "IPY_MODEL_d5e6cb2573454c94964b8d7caa5a229d",
            "value": " 201/? [00:36&lt;00:00,  5.65it/s, reward=0.905]"
          }
        },
        "a776f50ea9df4e2bb5e311ab6b9028df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71fff78494694f4f9b4565e74362c116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2be82f21ebf54be4bde9a0d5d64e100f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6781cbfdcd1f45bb8f7e016395ebcde1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d25fb1f7c0ae4c7d95ba796febfe6873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b70250a5da924ca2b5a54b9c177c3082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5e6cb2573454c94964b8d7caa5a229d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adriankobras/diffusion_models/blob/main/Kopie_von_diffusion_policy_vision_pusht_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Installing pip packages**\n",
        "#@markdown - Diffusion Model: [PyTorch](https://pytorch.org) & [HuggingFace diffusers](https://huggingface.co/docs/diffusers/index)\n",
        "#@markdown - Dataset Loading: [Zarr](https://zarr.readthedocs.io/en/stable/) & numcodecs\n",
        "#@markdown - Push-T Env: gym, pygame, pymunk & shapely\n",
        "!python --version\n",
        "!pip3 install \"jax[cuda12_local]==0.4.23\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "!pip3 install torch==1.13.1 torchvision==0.14.1 diffusers==0.18.2 \\\n",
        "scikit-image==0.19.3 scikit-video==1.1.11 zarr==2.12.0 numcodecs==0.10.2 \\\n",
        "pygame==2.1.2 pymunk==6.2.1 gym==0.26.2 shapely==1.8.4 \\\n",
        "&> /dev/null # mute output"
      ],
      "metadata": {
        "id": "2QwO2gAgiJS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b44dd5-151d-4d55-b998-5952f2f9218d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Collecting jax[cuda12_local]==0.4.23\n",
            "  Downloading jax-0.4.23-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_local]==0.4.23) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_local]==0.4.23) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_local]==0.4.23) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_local]==0.4.23) (1.11.4)\n",
            "Collecting jaxlib==0.4.23+cuda12.cudnn89 (from jax[cuda12_local]==0.4.23)\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.23%2Bcuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl (131.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jaxlib, jax\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.26+cuda12.cudnn89\n",
            "    Uninstalling jaxlib-0.4.26+cuda12.cudnn89:\n",
            "      Successfully uninstalled jaxlib-0.4.26+cuda12.cudnn89\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.26\n",
            "    Uninstalling jax-0.4.26:\n",
            "      Successfully uninstalled jax-0.4.26\n",
            "Successfully installed jax-0.4.23 jaxlib-0.4.23+cuda12.cudnn89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Imports**\n",
        "# diffusion policy import\n",
        "from typing import Tuple, Sequence, Dict, Union, Optional, Callable\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import collections\n",
        "import zarr\n",
        "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
        "from diffusers.training_utils import EMAModel\n",
        "from diffusers.optimization import get_scheduler\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# env import\n",
        "import gym\n",
        "from gym import spaces\n",
        "import pygame\n",
        "import pymunk\n",
        "import pymunk.pygame_util\n",
        "from pymunk.space_debug_draw_options import SpaceDebugColor\n",
        "from pymunk.vec2d import Vec2d\n",
        "import shapely.geometry as sg\n",
        "import cv2\n",
        "import skimage.transform as st\n",
        "from skvideo.io import vwrite\n",
        "from IPython.display import Video\n",
        "import gdown\n",
        "import os"
      ],
      "metadata": {
        "id": "VrX4VTl5pYNq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "3ea302ecb58e4ee793a18ece76a6f6a8",
            "ab6362e541434aa292e31fc00c5c379c",
            "d97efc62e6e54ff4ba4b5173d10b1601",
            "2e8b2a80b0eb470c838e9d6f66271827",
            "6144b327367b4c7f98c9678fb036965d",
            "7ca91d495d62414daed2b4e90b6ec949",
            "fec07e1832e849cfb7d444055a6a11c5",
            "8ae6eb79f11e49358cdaf4b8c8d6c88f",
            "97146c21e3d249b8977f1717cb31ac04",
            "ea552842de2940bfa7c5f48870ec01af",
            "a27fa8eb71d9418397e07ba0f420a32e"
          ]
        },
        "outputId": "50468da1-372d-412b-a175-f6221c76c4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ea302ecb58e4ee793a18ece76a6f6a8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Environment**\n",
        "#@markdown Defines a PyMunk-based Push-T environment `PushTEnv`.\n",
        "#@markdown And it's subclass `PushTImageEnv`.\n",
        "#@markdown\n",
        "#@markdown **Goal**: push the gray T-block into the green area.\n",
        "#@markdown\n",
        "#@markdown Adapted from [Implicit Behavior Cloning](https://implicitbc.github.io/)\n",
        "\n",
        "\n",
        "positive_y_is_up: bool = False\n",
        "\"\"\"Make increasing values of y point upwards.\n",
        "\n",
        "When True::\n",
        "\n",
        "    y\n",
        "    ^\n",
        "    |      . (3, 3)\n",
        "    |\n",
        "    |   . (2, 2)\n",
        "    |\n",
        "    +------ > x\n",
        "\n",
        "When False::\n",
        "\n",
        "    +------ > x\n",
        "    |\n",
        "    |   . (2, 2)\n",
        "    |\n",
        "    |      . (3, 3)\n",
        "    v\n",
        "    y\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def to_pygame(p: Tuple[float, float], surface: pygame.Surface) -> Tuple[int, int]:\n",
        "    \"\"\"Convenience method to convert pymunk coordinates to pygame surface\n",
        "    local coordinates.\n",
        "\n",
        "    Note that in case positive_y_is_up is False, this function wont actually do\n",
        "    anything except converting the point to integers.\n",
        "    \"\"\"\n",
        "    if positive_y_is_up:\n",
        "        return round(p[0]), surface.get_height() - round(p[1])\n",
        "    else:\n",
        "        return round(p[0]), round(p[1])\n",
        "\n",
        "\n",
        "def light_color(color: SpaceDebugColor):\n",
        "    color = np.minimum(1.2 * np.float32([color.r, color.g, color.b, color.a]), np.float32([255]))\n",
        "    color = SpaceDebugColor(r=color[0], g=color[1], b=color[2], a=color[3])\n",
        "    return color\n",
        "\n",
        "class DrawOptions(pymunk.SpaceDebugDrawOptions):\n",
        "    def __init__(self, surface: pygame.Surface) -> None:\n",
        "        \"\"\"Draw a pymunk.Space on a pygame.Surface object.\n",
        "\n",
        "        Typical usage::\n",
        "\n",
        "        >>> import pymunk\n",
        "        >>> surface = pygame.Surface((10,10))\n",
        "        >>> space = pymunk.Space()\n",
        "        >>> options = pymunk.pygame_util.DrawOptions(surface)\n",
        "        >>> space.debug_draw(options)\n",
        "\n",
        "        You can control the color of a shape by setting shape.color to the color\n",
        "        you want it drawn in::\n",
        "\n",
        "        >>> c = pymunk.Circle(None, 10)\n",
        "        >>> c.color = pygame.Color(\"pink\")\n",
        "\n",
        "        See pygame_util.demo.py for a full example\n",
        "\n",
        "        Since pygame uses a coordiante system where y points down (in contrast\n",
        "        to many other cases), you either have to make the physics simulation\n",
        "        with Pymunk also behave in that way, or flip everything when you draw.\n",
        "\n",
        "        The easiest is probably to just make the simulation behave the same\n",
        "        way as Pygame does. In that way all coordinates used are in the same\n",
        "        orientation and easy to reason about::\n",
        "\n",
        "        >>> space = pymunk.Space()\n",
        "        >>> space.gravity = (0, -1000)\n",
        "        >>> body = pymunk.Body()\n",
        "        >>> body.position = (0, 0) # will be positioned in the top left corner\n",
        "        >>> space.debug_draw(options)\n",
        "\n",
        "        To flip the drawing its possible to set the module property\n",
        "        :py:data:`positive_y_is_up` to True. Then the pygame drawing will flip\n",
        "        the simulation upside down before drawing::\n",
        "\n",
        "        >>> positive_y_is_up = True\n",
        "        >>> body = pymunk.Body()\n",
        "        >>> body.position = (0, 0)\n",
        "        >>> # Body will be position in bottom left corner\n",
        "\n",
        "        :Parameters:\n",
        "                surface : pygame.Surface\n",
        "                    Surface that the objects will be drawn on\n",
        "        \"\"\"\n",
        "        self.surface = surface\n",
        "        super(DrawOptions, self).__init__()\n",
        "\n",
        "    def draw_circle(\n",
        "        self,\n",
        "        pos: Vec2d,\n",
        "        angle: float,\n",
        "        radius: float,\n",
        "        outline_color: SpaceDebugColor,\n",
        "        fill_color: SpaceDebugColor,\n",
        "    ) -> None:\n",
        "        p = to_pygame(pos, self.surface)\n",
        "\n",
        "        pygame.draw.circle(self.surface, fill_color.as_int(), p, round(radius), 0)\n",
        "        pygame.draw.circle(self.surface, light_color(fill_color).as_int(), p, round(radius-4), 0)\n",
        "\n",
        "        circle_edge = pos + Vec2d(radius, 0).rotated(angle)\n",
        "        p2 = to_pygame(circle_edge, self.surface)\n",
        "        line_r = 2 if radius > 20 else 1\n",
        "        # pygame.draw.lines(self.surface, outline_color.as_int(), False, [p, p2], line_r)\n",
        "\n",
        "    def draw_segment(self, a: Vec2d, b: Vec2d, color: SpaceDebugColor) -> None:\n",
        "        p1 = to_pygame(a, self.surface)\n",
        "        p2 = to_pygame(b, self.surface)\n",
        "\n",
        "        pygame.draw.aalines(self.surface, color.as_int(), False, [p1, p2])\n",
        "\n",
        "    def draw_fat_segment(\n",
        "        self,\n",
        "        a: Tuple[float, float],\n",
        "        b: Tuple[float, float],\n",
        "        radius: float,\n",
        "        outline_color: SpaceDebugColor,\n",
        "        fill_color: SpaceDebugColor,\n",
        "    ) -> None:\n",
        "        p1 = to_pygame(a, self.surface)\n",
        "        p2 = to_pygame(b, self.surface)\n",
        "\n",
        "        r = round(max(1, radius * 2))\n",
        "        pygame.draw.lines(self.surface, fill_color.as_int(), False, [p1, p2], r)\n",
        "        if r > 2:\n",
        "            orthog = [abs(p2[1] - p1[1]), abs(p2[0] - p1[0])]\n",
        "            if orthog[0] == 0 and orthog[1] == 0:\n",
        "                return\n",
        "            scale = radius / (orthog[0] * orthog[0] + orthog[1] * orthog[1]) ** 0.5\n",
        "            orthog[0] = round(orthog[0] * scale)\n",
        "            orthog[1] = round(orthog[1] * scale)\n",
        "            points = [\n",
        "                (p1[0] - orthog[0], p1[1] - orthog[1]),\n",
        "                (p1[0] + orthog[0], p1[1] + orthog[1]),\n",
        "                (p2[0] + orthog[0], p2[1] + orthog[1]),\n",
        "                (p2[0] - orthog[0], p2[1] - orthog[1]),\n",
        "            ]\n",
        "            pygame.draw.polygon(self.surface, fill_color.as_int(), points)\n",
        "            pygame.draw.circle(\n",
        "                self.surface,\n",
        "                fill_color.as_int(),\n",
        "                (round(p1[0]), round(p1[1])),\n",
        "                round(radius),\n",
        "            )\n",
        "            pygame.draw.circle(\n",
        "                self.surface,\n",
        "                fill_color.as_int(),\n",
        "                (round(p2[0]), round(p2[1])),\n",
        "                round(radius),\n",
        "            )\n",
        "\n",
        "    def draw_polygon(\n",
        "        self,\n",
        "        verts: Sequence[Tuple[float, float]],\n",
        "        radius: float,\n",
        "        outline_color: SpaceDebugColor,\n",
        "        fill_color: SpaceDebugColor,\n",
        "    ) -> None:\n",
        "        ps = [to_pygame(v, self.surface) for v in verts]\n",
        "        ps += [ps[0]]\n",
        "\n",
        "        radius = 2\n",
        "        pygame.draw.polygon(self.surface, light_color(fill_color).as_int(), ps)\n",
        "\n",
        "        if radius > 0:\n",
        "            for i in range(len(verts)):\n",
        "                a = verts[i]\n",
        "                b = verts[(i + 1) % len(verts)]\n",
        "                self.draw_fat_segment(a, b, radius, fill_color, fill_color)\n",
        "\n",
        "    def draw_dot(\n",
        "        self, size: float, pos: Tuple[float, float], color: SpaceDebugColor\n",
        "    ) -> None:\n",
        "        p = to_pygame(pos, self.surface)\n",
        "        pygame.draw.circle(self.surface, color.as_int(), p, round(size), 0)\n",
        "\n",
        "\n",
        "def pymunk_to_shapely(body, shapes):\n",
        "    geoms = list()\n",
        "    for shape in shapes:\n",
        "        if isinstance(shape, pymunk.shapes.Poly):\n",
        "            verts = [body.local_to_world(v) for v in shape.get_vertices()]\n",
        "            verts += [verts[0]]\n",
        "            geoms.append(sg.Polygon(verts))\n",
        "        else:\n",
        "            raise RuntimeError(f'Unsupported shape type {type(shape)}')\n",
        "    geom = sg.MultiPolygon(geoms)\n",
        "    return geom\n",
        "\n",
        "# env\n",
        "class PushTEnv(gym.Env):\n",
        "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 10}\n",
        "    reward_range = (0., 1.)\n",
        "\n",
        "    def __init__(self,\n",
        "            legacy=False,\n",
        "            block_cog=None, damping=None,\n",
        "            render_action=True,\n",
        "            render_size=96,\n",
        "            reset_to_state=None\n",
        "        ):\n",
        "        self._seed = None\n",
        "        self.seed()\n",
        "        self.window_size = ws = 512  # The size of the PyGame window\n",
        "        self.render_size = render_size\n",
        "        self.sim_hz = 100\n",
        "        # Local controller params.\n",
        "        self.k_p, self.k_v = 100, 20    # PD control.z\n",
        "        self.control_hz = self.metadata['video.frames_per_second']\n",
        "        # legcay set_state for data compatiblity\n",
        "        self.legacy = legacy\n",
        "\n",
        "        # agent_pos, block_pos, block_angle\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.array([0,0,0,0,0], dtype=np.float64),\n",
        "            high=np.array([ws,ws,ws,ws,np.pi*2], dtype=np.float64),\n",
        "            shape=(5,),\n",
        "            dtype=np.float64\n",
        "        )\n",
        "\n",
        "        # positional goal for agent\n",
        "        self.action_space = spaces.Box(\n",
        "            low=np.array([0,0], dtype=np.float64),\n",
        "            high=np.array([ws,ws], dtype=np.float64),\n",
        "            shape=(2,),\n",
        "            dtype=np.float64\n",
        "        )\n",
        "\n",
        "        self.block_cog = block_cog\n",
        "        self.damping = damping\n",
        "        self.render_action = render_action\n",
        "\n",
        "        \"\"\"\n",
        "        If human-rendering is used, `self.window` will be a reference\n",
        "        to the window that we draw to. `self.clock` will be a clock that is used\n",
        "        to ensure that the environment is rendered at the correct framerate in\n",
        "        human-mode. They will remain `None` until human-mode is used for the\n",
        "        first time.\n",
        "        \"\"\"\n",
        "        self.window = None\n",
        "        self.clock = None\n",
        "        self.screen = None\n",
        "\n",
        "        self.space = None\n",
        "        self.teleop = None\n",
        "        self.render_buffer = None\n",
        "        self.latest_action = None\n",
        "        self.reset_to_state = reset_to_state\n",
        "\n",
        "    def reset(self):\n",
        "        seed = self._seed\n",
        "        self._setup()\n",
        "        if self.block_cog is not None:\n",
        "            self.block.center_of_gravity = self.block_cog\n",
        "        if self.damping is not None:\n",
        "            self.space.damping = self.damping\n",
        "\n",
        "        # use legacy RandomState for compatiblity\n",
        "        state = self.reset_to_state\n",
        "        if state is None:\n",
        "            rs = np.random.RandomState(seed=seed)\n",
        "            state = np.array([\n",
        "                rs.randint(50, 450), rs.randint(50, 450),\n",
        "                rs.randint(100, 400), rs.randint(100, 400),\n",
        "                rs.randn() * 2 * np.pi - np.pi\n",
        "                ])\n",
        "        self._set_state(state)\n",
        "\n",
        "        obs = self._get_obs()\n",
        "        info = self._get_info()\n",
        "        return obs, info\n",
        "\n",
        "    def step(self, action):\n",
        "        dt = 1.0 / self.sim_hz\n",
        "        self.n_contact_points = 0\n",
        "        n_steps = self.sim_hz // self.control_hz\n",
        "        if action is not None:\n",
        "            self.latest_action = action\n",
        "            for i in range(n_steps):\n",
        "                # Step PD control.\n",
        "                # self.agent.velocity = self.k_p * (act - self.agent.position)    # P control works too.\n",
        "                acceleration = self.k_p * (action - self.agent.position) + self.k_v * (Vec2d(0, 0) - self.agent.velocity)\n",
        "                self.agent.velocity += acceleration * dt\n",
        "\n",
        "                # Step physics.\n",
        "                self.space.step(dt)\n",
        "\n",
        "        # compute reward\n",
        "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
        "        goal_geom = pymunk_to_shapely(goal_body, self.block.shapes)\n",
        "        block_geom = pymunk_to_shapely(self.block, self.block.shapes)\n",
        "\n",
        "        intersection_area = goal_geom.intersection(block_geom).area\n",
        "        goal_area = goal_geom.area\n",
        "        coverage = intersection_area / goal_area\n",
        "        reward = np.clip(coverage / self.success_threshold, 0, 1)\n",
        "        done = coverage > self.success_threshold\n",
        "        terminated = done\n",
        "        truncated = done\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "    def render(self, mode):\n",
        "        return self._render_frame(mode)\n",
        "\n",
        "    def teleop_agent(self):\n",
        "        TeleopAgent = collections.namedtuple('TeleopAgent', ['act'])\n",
        "        def act(obs):\n",
        "            act = None\n",
        "            mouse_position = pymunk.pygame_util.from_pygame(Vec2d(*pygame.mouse.get_pos()), self.screen)\n",
        "            if self.teleop or (mouse_position - self.agent.position).length < 30:\n",
        "                self.teleop = True\n",
        "                act = mouse_position\n",
        "            return act\n",
        "        return TeleopAgent(act)\n",
        "\n",
        "    def _get_obs(self):\n",
        "        obs = np.array(\n",
        "            tuple(self.agent.position) \\\n",
        "            + tuple(self.block.position) \\\n",
        "            + (self.block.angle % (2 * np.pi),))\n",
        "        return obs\n",
        "\n",
        "    def _get_goal_pose_body(self, pose):\n",
        "        mass = 1\n",
        "        inertia = pymunk.moment_for_box(mass, (50, 100))\n",
        "        body = pymunk.Body(mass, inertia)\n",
        "        # preserving the legacy assignment order for compatibility\n",
        "        # the order here dosn't matter somehow, maybe because CoM is aligned with body origin\n",
        "        body.position = pose[:2].tolist()\n",
        "        body.angle = pose[2]\n",
        "        return body\n",
        "\n",
        "    def _get_info(self):\n",
        "        n_steps = self.sim_hz // self.control_hz\n",
        "        n_contact_points_per_step = int(np.ceil(self.n_contact_points / n_steps))\n",
        "        info = {\n",
        "            'pos_agent': np.array(self.agent.position),\n",
        "            'vel_agent': np.array(self.agent.velocity),\n",
        "            'block_pose': np.array(list(self.block.position) + [self.block.angle]),\n",
        "            'goal_pose': self.goal_pose,\n",
        "            'n_contacts': n_contact_points_per_step}\n",
        "        return info\n",
        "\n",
        "    def _render_frame(self, mode):\n",
        "\n",
        "        if self.window is None and mode == \"human\":\n",
        "            pygame.init()\n",
        "            pygame.display.init()\n",
        "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
        "        if self.clock is None and mode == \"human\":\n",
        "            self.clock = pygame.time.Clock()\n",
        "\n",
        "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
        "        canvas.fill((255, 255, 255))\n",
        "        self.screen = canvas\n",
        "\n",
        "        draw_options = DrawOptions(canvas)\n",
        "\n",
        "        # Draw goal pose.\n",
        "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
        "        for shape in self.block.shapes:\n",
        "            goal_points = [pymunk.pygame_util.to_pygame(goal_body.local_to_world(v), draw_options.surface) for v in shape.get_vertices()]\n",
        "            goal_points += [goal_points[0]]\n",
        "            pygame.draw.polygon(canvas, self.goal_color, goal_points)\n",
        "\n",
        "        # Draw agent and block.\n",
        "        self.space.debug_draw(draw_options)\n",
        "\n",
        "        if mode == \"human\":\n",
        "            # The following line copies our drawings from `canvas` to the visible window\n",
        "            self.window.blit(canvas, canvas.get_rect())\n",
        "            pygame.event.pump()\n",
        "            pygame.display.update()\n",
        "\n",
        "            # the clock is aleady ticked during in step for \"human\"\n",
        "\n",
        "\n",
        "        img = np.transpose(\n",
        "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
        "            )\n",
        "        img = cv2.resize(img, (self.render_size, self.render_size))\n",
        "        if self.render_action:\n",
        "            if self.render_action and (self.latest_action is not None):\n",
        "                action = np.array(self.latest_action)\n",
        "                coord = (action / 512 * 96).astype(np.int32)\n",
        "                marker_size = int(8/96*self.render_size)\n",
        "                thickness = int(1/96*self.render_size)\n",
        "                cv2.drawMarker(img, coord,\n",
        "                    color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
        "                    markerSize=marker_size, thickness=thickness)\n",
        "        return img\n",
        "\n",
        "\n",
        "    def close(self):\n",
        "        if self.window is not None:\n",
        "            pygame.display.quit()\n",
        "            pygame.quit()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        if seed is None:\n",
        "            seed = np.random.randint(0,25536)\n",
        "        self._seed = seed\n",
        "        self.np_random = np.random.default_rng(seed)\n",
        "\n",
        "    def _handle_collision(self, arbiter, space, data):\n",
        "        self.n_contact_points += len(arbiter.contact_point_set.points)\n",
        "\n",
        "    def _set_state(self, state):\n",
        "        if isinstance(state, np.ndarray):\n",
        "            state = state.tolist()\n",
        "        pos_agent = state[:2]\n",
        "        pos_block = state[2:4]\n",
        "        rot_block = state[4]\n",
        "        self.agent.position = pos_agent\n",
        "        # setting angle rotates with respect to center of mass\n",
        "        # therefore will modify the geometric position\n",
        "        # if not the same as CoM\n",
        "        # therefore should be modified first.\n",
        "        if self.legacy:\n",
        "            # for compatiblity with legacy data\n",
        "            self.block.position = pos_block\n",
        "            self.block.angle = rot_block\n",
        "        else:\n",
        "            self.block.angle = rot_block\n",
        "            self.block.position = pos_block\n",
        "\n",
        "        # Run physics to take effect\n",
        "        self.space.step(1.0 / self.sim_hz)\n",
        "\n",
        "    def _set_state_local(self, state_local):\n",
        "        agent_pos_local = state_local[:2]\n",
        "        block_pose_local = state_local[2:]\n",
        "        tf_img_obj = st.AffineTransform(\n",
        "            translation=self.goal_pose[:2],\n",
        "            rotation=self.goal_pose[2])\n",
        "        tf_obj_new = st.AffineTransform(\n",
        "            translation=block_pose_local[:2],\n",
        "            rotation=block_pose_local[2]\n",
        "        )\n",
        "        tf_img_new = st.AffineTransform(\n",
        "            matrix=tf_img_obj.params @ tf_obj_new.params\n",
        "        )\n",
        "        agent_pos_new = tf_img_new(agent_pos_local)\n",
        "        new_state = np.array(\n",
        "            list(agent_pos_new[0]) + list(tf_img_new.translation) \\\n",
        "                + [tf_img_new.rotation])\n",
        "        self._set_state(new_state)\n",
        "        return new_state\n",
        "\n",
        "    def _setup(self):\n",
        "        self.space = pymunk.Space()\n",
        "        self.space.gravity = 0, 0\n",
        "        self.space.damping = 0\n",
        "        self.teleop = False\n",
        "        self.render_buffer = list()\n",
        "\n",
        "        # Add walls.\n",
        "        walls = [\n",
        "            self._add_segment((5, 506), (5, 5), 2),\n",
        "            self._add_segment((5, 5), (506, 5), 2),\n",
        "            self._add_segment((506, 5), (506, 506), 2),\n",
        "            self._add_segment((5, 506), (506, 506), 2)\n",
        "        ]\n",
        "        self.space.add(*walls)\n",
        "\n",
        "        # Add agent, block, and goal zone.\n",
        "        self.agent = self.add_circle((256, 400), 15)\n",
        "        self.block = self.add_tee((256, 300), 0)\n",
        "        self.goal_color = pygame.Color('LightGreen')\n",
        "        self.goal_pose = np.array([256,256,np.pi/4])  # x, y, theta (in radians)\n",
        "\n",
        "        # Add collision handeling\n",
        "        self.collision_handeler = self.space.add_collision_handler(0, 0)\n",
        "        self.collision_handeler.post_solve = self._handle_collision\n",
        "        self.n_contact_points = 0\n",
        "\n",
        "        self.max_score = 50 * 100\n",
        "        self.success_threshold = 0.95    # 95% coverage.\n",
        "\n",
        "    def _add_segment(self, a, b, radius):\n",
        "        shape = pymunk.Segment(self.space.static_body, a, b, radius)\n",
        "        shape.color = pygame.Color('LightGray')    # https://htmlcolorcodes.com/color-names\n",
        "        return shape\n",
        "\n",
        "    def add_circle(self, position, radius):\n",
        "        body = pymunk.Body(body_type=pymunk.Body.KINEMATIC)\n",
        "        body.position = position\n",
        "        body.friction = 1\n",
        "        shape = pymunk.Circle(body, radius)\n",
        "        shape.color = pygame.Color('RoyalBlue')\n",
        "        self.space.add(body, shape)\n",
        "        return body\n",
        "\n",
        "    def add_box(self, position, height, width):\n",
        "        mass = 1\n",
        "        inertia = pymunk.moment_for_box(mass, (height, width))\n",
        "        body = pymunk.Body(mass, inertia)\n",
        "        body.position = position\n",
        "        shape = pymunk.Poly.create_box(body, (height, width))\n",
        "        shape.color = pygame.Color('LightSlateGray')\n",
        "        self.space.add(body, shape)\n",
        "        return body\n",
        "\n",
        "    def add_tee(self, position, angle, scale=30, color='LightSlateGray', mask=pymunk.ShapeFilter.ALL_MASKS()):\n",
        "        mass = 1\n",
        "        length = 4\n",
        "        vertices1 = [(-length*scale/2, scale),\n",
        "                                 ( length*scale/2, scale),\n",
        "                                 ( length*scale/2, 0),\n",
        "                                 (-length*scale/2, 0)]\n",
        "        inertia1 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
        "        vertices2 = [(-scale/2, scale),\n",
        "                                 (-scale/2, length*scale),\n",
        "                                 ( scale/2, length*scale),\n",
        "                                 ( scale/2, scale)]\n",
        "        inertia2 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
        "        body = pymunk.Body(mass, inertia1 + inertia2)\n",
        "        shape1 = pymunk.Poly(body, vertices1)\n",
        "        shape2 = pymunk.Poly(body, vertices2)\n",
        "        shape1.color = pygame.Color(color)\n",
        "        shape2.color = pygame.Color(color)\n",
        "        shape1.filter = pymunk.ShapeFilter(mask=mask)\n",
        "        shape2.filter = pymunk.ShapeFilter(mask=mask)\n",
        "        body.center_of_gravity = (shape1.center_of_gravity + shape2.center_of_gravity) / 2\n",
        "        body.position = position\n",
        "        body.angle = angle\n",
        "        body.friction = 1\n",
        "        self.space.add(body, shape1, shape2)\n",
        "        return body\n",
        "\n",
        "\n",
        "class PushTImageEnv(PushTEnv):\n",
        "    metadata = {\"render.modes\": [\"rgb_array\"], \"video.frames_per_second\": 10}\n",
        "\n",
        "    def __init__(self,\n",
        "            legacy=False,\n",
        "            block_cog=None,\n",
        "            damping=None,\n",
        "            render_size=96):\n",
        "        super().__init__(\n",
        "            legacy=legacy,\n",
        "            block_cog=block_cog,\n",
        "            damping=damping,\n",
        "            render_size=render_size,\n",
        "            render_action=False)\n",
        "        ws = self.window_size\n",
        "        self.observation_space = spaces.Dict({\n",
        "            'image': spaces.Box(\n",
        "                low=0,\n",
        "                high=1,\n",
        "                shape=(3,render_size,render_size),\n",
        "                dtype=np.float32\n",
        "            ),\n",
        "            'agent_pos': spaces.Box(\n",
        "                low=0,\n",
        "                high=ws,\n",
        "                shape=(2,),\n",
        "                dtype=np.float32\n",
        "            )\n",
        "        })\n",
        "        self.render_cache = None\n",
        "\n",
        "    def _get_obs(self):\n",
        "        img = super()._render_frame(mode='rgb_array')\n",
        "\n",
        "        agent_pos = np.array(self.agent.position)\n",
        "        img_obs = np.moveaxis(img.astype(np.float32) / 255, -1, 0)\n",
        "        obs = {\n",
        "            'image': img_obs,\n",
        "            'agent_pos': agent_pos\n",
        "        }\n",
        "\n",
        "        # draw action\n",
        "        if self.latest_action is not None:\n",
        "            action = np.array(self.latest_action)\n",
        "            coord = (action / 512 * 96).astype(np.int32)\n",
        "            marker_size = int(8/96*self.render_size)\n",
        "            thickness = int(1/96*self.render_size)\n",
        "            cv2.drawMarker(img, coord,\n",
        "                color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
        "                markerSize=marker_size, thickness=thickness)\n",
        "        self.render_cache = img\n",
        "\n",
        "        return obs\n",
        "\n",
        "    def render(self, mode):\n",
        "        assert mode == 'rgb_array'\n",
        "\n",
        "        if self.render_cache is None:\n",
        "            self._get_obs()\n",
        "\n",
        "        return self.render_cache\n",
        "\n"
      ],
      "metadata": {
        "id": "L5E-nR6ornyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Env Demo**\n",
        "#@markdown Standard Gym Env (0.21.0 API)\n",
        "\n",
        "# 0. create env object\n",
        "env = PushTImageEnv()\n",
        "\n",
        "# 1. seed env for initial state.\n",
        "# Seed 0-200 are used for the demonstration dataset.\n",
        "env.seed(1000)\n",
        "\n",
        "# 2. must reset before use\n",
        "obs, info = env.reset()\n",
        "\n",
        "# 3. 2D positional action space [0,512]\n",
        "action = env.action_space.sample()\n",
        "\n",
        "# 4. Standard gym step method\n",
        "obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "# prints and explains each dimension of the observation and action vectors\n",
        "with np.printoptions(precision=4, suppress=True, threshold=5):\n",
        "    print(\"obs['image'].shape:\", obs['image'].shape, \"float32, [0,1]\")\n",
        "    print(\"obs['agent_pos'].shape:\", obs['agent_pos'].shape, \"float32, [0,512]\")\n",
        "    print(\"action.shape: \", action.shape, \"float32, [0,512]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OknH8Qfqrtc9",
        "outputId": "df777269-9184-48e3-edd8-92d68faa5f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obs['image'].shape: (3, 96, 96) float32, [0,1]\n",
            "obs['agent_pos'].shape: (2,) float32, [0,512]\n",
            "action.shape:  (2,) float32, [0,512]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Dataset**\n",
        "#@markdown\n",
        "#@markdown Defines `PushTImageDataset` and helper functions\n",
        "#@markdown\n",
        "#@markdown The dataset class\n",
        "#@markdown - Load data ((image, agent_pos), action) from a zarr storage\n",
        "#@markdown - Normalizes each dimension of agent_pos and action to [-1,1]\n",
        "#@markdown - Returns\n",
        "#@markdown  - All possible segments with length `pred_horizon`\n",
        "#@markdown  - Pads the beginning and the end of each episode with repetition\n",
        "#@markdown  - key `image`: shape (obs_hoirzon, 3, 96, 96)\n",
        "#@markdown  - key `agent_pos`: shape (obs_hoirzon, 2)\n",
        "#@markdown  - key `action`: shape (pred_horizon, 2)\n",
        "\n",
        "def create_sample_indices(\n",
        "        episode_ends:np.ndarray, sequence_length:int,\n",
        "        pad_before: int=0, pad_after: int=0):\n",
        "    indices = list()\n",
        "    for i in range(len(episode_ends)):\n",
        "        start_idx = 0\n",
        "        if i > 0:\n",
        "            start_idx = episode_ends[i-1]\n",
        "        end_idx = episode_ends[i]\n",
        "        episode_length = end_idx - start_idx\n",
        "\n",
        "        min_start = -pad_before\n",
        "        max_start = episode_length - sequence_length + pad_after\n",
        "\n",
        "        # range stops one idx before end\n",
        "        for idx in range(min_start, max_start+1):\n",
        "            buffer_start_idx = max(idx, 0) + start_idx\n",
        "            buffer_end_idx = min(idx+sequence_length, episode_length) + start_idx\n",
        "            start_offset = buffer_start_idx - (idx+start_idx)\n",
        "            end_offset = (idx+sequence_length+start_idx) - buffer_end_idx\n",
        "            sample_start_idx = 0 + start_offset\n",
        "            sample_end_idx = sequence_length - end_offset\n",
        "            indices.append([\n",
        "                buffer_start_idx, buffer_end_idx,\n",
        "                sample_start_idx, sample_end_idx])\n",
        "    indices = np.array(indices)\n",
        "    return indices\n",
        "\n",
        "\n",
        "def sample_sequence(train_data, sequence_length,\n",
        "                    buffer_start_idx, buffer_end_idx,\n",
        "                    sample_start_idx, sample_end_idx):\n",
        "    result = dict()\n",
        "    for key, input_arr in train_data.items():\n",
        "        sample = input_arr[buffer_start_idx:buffer_end_idx]\n",
        "        data = sample\n",
        "        if (sample_start_idx > 0) or (sample_end_idx < sequence_length):\n",
        "            data = np.zeros(\n",
        "                shape=(sequence_length,) + input_arr.shape[1:],\n",
        "                dtype=input_arr.dtype)\n",
        "            if sample_start_idx > 0:\n",
        "                data[:sample_start_idx] = sample[0]\n",
        "            if sample_end_idx < sequence_length:\n",
        "                data[sample_end_idx:] = sample[-1]\n",
        "            data[sample_start_idx:sample_end_idx] = sample\n",
        "        result[key] = data\n",
        "    return result\n",
        "\n",
        "# normalize data\n",
        "def get_data_stats(data):\n",
        "    data = data.reshape(-1,data.shape[-1])\n",
        "    stats = {\n",
        "        'min': np.min(data, axis=0),\n",
        "        'max': np.max(data, axis=0)\n",
        "    }\n",
        "    return stats\n",
        "\n",
        "def normalize_data(data, stats):\n",
        "    # nomalize to [0,1]\n",
        "    ndata = (data - stats['min']) / (stats['max'] - stats['min'])\n",
        "    # normalize to [-1, 1]\n",
        "    ndata = ndata * 2 - 1\n",
        "    return ndata\n",
        "\n",
        "def unnormalize_data(ndata, stats):\n",
        "    ndata = (ndata + 1) / 2\n",
        "    data = ndata * (stats['max'] - stats['min']) + stats['min']\n",
        "    return data\n",
        "\n",
        "# dataset\n",
        "class PushTImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,\n",
        "                 dataset_path: str,\n",
        "                 pred_horizon: int,\n",
        "                 obs_horizon: int,\n",
        "                 action_horizon: int):\n",
        "\n",
        "        # read from zarr dataset\n",
        "        dataset_root = zarr.open(dataset_path, 'r')\n",
        "\n",
        "        # float32, [0,1], (N,96,96,3)\n",
        "        train_image_data = dataset_root['data']['img'][:]\n",
        "        train_image_data = np.moveaxis(train_image_data, -1,1)\n",
        "        # (N,3,96,96)\n",
        "\n",
        "        # (N, D)\n",
        "        train_data = {\n",
        "            # first two dims of state vector are agent (i.e. gripper) locations\n",
        "            'agent_pos': dataset_root['data']['state'][:,:2],\n",
        "            'action': dataset_root['data']['action'][:]\n",
        "        }\n",
        "        episode_ends = dataset_root['meta']['episode_ends'][:]\n",
        "\n",
        "        # compute start and end of each state-action sequence\n",
        "        # also handles padding\n",
        "        indices = create_sample_indices(\n",
        "            episode_ends=episode_ends,\n",
        "            sequence_length=pred_horizon,\n",
        "            pad_before=obs_horizon-1,\n",
        "            pad_after=action_horizon-1)\n",
        "\n",
        "        # compute statistics and normalized data to [-1,1]\n",
        "        stats = dict()\n",
        "        normalized_train_data = dict()\n",
        "        for key, data in train_data.items():\n",
        "            stats[key] = get_data_stats(data)\n",
        "            normalized_train_data[key] = normalize_data(data, stats[key])\n",
        "\n",
        "        # images are already normalized\n",
        "        normalized_train_data['image'] = train_image_data\n",
        "\n",
        "        self.indices = indices\n",
        "        self.stats = stats\n",
        "        self.normalized_train_data = normalized_train_data\n",
        "        self.pred_horizon = pred_horizon\n",
        "        self.action_horizon = action_horizon\n",
        "        self.obs_horizon = obs_horizon\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get the start/end indices for this datapoint\n",
        "        buffer_start_idx, buffer_end_idx, \\\n",
        "            sample_start_idx, sample_end_idx = self.indices[idx]\n",
        "\n",
        "        # get nomralized data using these indices\n",
        "        nsample = sample_sequence(\n",
        "            train_data=self.normalized_train_data,\n",
        "            sequence_length=self.pred_horizon,\n",
        "            buffer_start_idx=buffer_start_idx,\n",
        "            buffer_end_idx=buffer_end_idx,\n",
        "            sample_start_idx=sample_start_idx,\n",
        "            sample_end_idx=sample_end_idx\n",
        "        )\n",
        "\n",
        "        # discard unused observations\n",
        "        nsample['image'] = nsample['image'][:self.obs_horizon,:]\n",
        "        nsample['agent_pos'] = nsample['agent_pos'][:self.obs_horizon,:]\n",
        "        return nsample\n"
      ],
      "metadata": {
        "id": "vHepJOFBucwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Dataset Demo**\n",
        "\n",
        "# download demonstration data from Google Drive\n",
        "dataset_path = \"pusht_cchi_v7_replay.zarr.zip\"\n",
        "if not os.path.isfile(dataset_path):\n",
        "    id = \"1KY1InLurpMvJDRb14L9NlXT_fEsCvVUq&confirm=t\"\n",
        "    gdown.download(id=id, output=dataset_path, quiet=False)\n",
        "\n",
        "# parameters\n",
        "pred_horizon = 16\n",
        "obs_horizon = 2\n",
        "action_horizon = 8\n",
        "#|o|o|                             observations: 2\n",
        "#| |a|a|a|a|a|a|a|a|               actions executed: 8\n",
        "#|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p| actions predicted: 16\n",
        "\n",
        "# create dataset from file\n",
        "dataset = PushTImageDataset(\n",
        "    dataset_path=dataset_path,\n",
        "    pred_horizon=pred_horizon,\n",
        "    obs_horizon=obs_horizon,\n",
        "    action_horizon=action_horizon\n",
        ")\n",
        "# save training data statistics (min, max) for each dim\n",
        "stats = dataset.stats\n",
        "\n",
        "# create dataloader\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=64,\n",
        "    num_workers=4,\n",
        "    shuffle=True,\n",
        "    # accelerate cpu-gpu transfer\n",
        "    pin_memory=True,\n",
        "    # don't kill worker process afte each epoch\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "# visualize data in batch\n",
        "batch = next(iter(dataloader))\n",
        "print(\"batch['image'].shape:\", batch['image'].shape)\n",
        "print(\"batch['agent_pos'].shape:\", batch['agent_pos'].shape)\n",
        "print(\"batch['action'].shape\", batch['action'].shape)"
      ],
      "metadata": {
        "id": "9ZiHF3lzvB6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84e6b67-174f-41aa-cd7c-0de3cd81d7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KY1InLurpMvJDRb14L9NlXT_fEsCvVUq&confirm=t\n",
            "To: /content/pusht_cchi_v7_replay.zarr.zip\n",
            "100%|██████████| 31.1M/31.1M [00:01<00:00, 27.8MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch['image'].shape: torch.Size([64, 2, 3, 96, 96])\n",
            "batch['agent_pos'].shape: torch.Size([64, 2, 2])\n",
            "batch['action'].shape torch.Size([64, 16, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Network**\n",
        "#@markdown\n",
        "#@markdown Defines a 1D UNet architecture `ConditionalUnet1D`\n",
        "#@markdown as the noies prediction network\n",
        "#@markdown\n",
        "#@markdown Components\n",
        "#@markdown - `SinusoidalPosEmb` Positional encoding for the diffusion iteration k\n",
        "#@markdown - `Downsample1d` Strided convolution to reduce temporal resolution\n",
        "#@markdown - `Upsample1d` Transposed convolution to increase temporal resolution\n",
        "#@markdown - `Conv1dBlock` Conv1d --> GroupNorm --> Mish\n",
        "#@markdown - `ConditionalResidualBlock1D` Takes two inputs `x` and `cond`. \\\n",
        "#@markdown `x` is passed through 2 `Conv1dBlock` stacked together with residual connection.\n",
        "#@markdown `cond` is applied to `x` with [FiLM](https://arxiv.org/abs/1709.07871) conditioning.\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = x[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "\n",
        "class Downsample1d(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class Upsample1d(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Conv1dBlock(nn.Module):\n",
        "    '''\n",
        "        Conv1d --> GroupNorm --> Mish\n",
        "    '''\n",
        "\n",
        "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv1d(inp_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
        "            nn.GroupNorm(n_groups, out_channels),\n",
        "            nn.Mish(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class ConditionalResidualBlock1D(nn.Module):\n",
        "    def __init__(self,\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            cond_dim,\n",
        "            kernel_size=3,\n",
        "            n_groups=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Conv1dBlock(in_channels, out_channels, kernel_size, n_groups=n_groups),\n",
        "            Conv1dBlock(out_channels, out_channels, kernel_size, n_groups=n_groups),\n",
        "        ])\n",
        "\n",
        "        # FiLM modulation https://arxiv.org/abs/1709.07871\n",
        "        # predicts per-channel scale and bias\n",
        "        cond_channels = out_channels * 2\n",
        "        self.out_channels = out_channels\n",
        "        self.cond_encoder = nn.Sequential(\n",
        "            nn.Mish(),\n",
        "            nn.Linear(cond_dim, cond_channels),\n",
        "            nn.Unflatten(-1, (-1, 1))\n",
        "        )\n",
        "\n",
        "        # make sure dimensions compatible\n",
        "        self.residual_conv = nn.Conv1d(in_channels, out_channels, 1) \\\n",
        "            if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        '''\n",
        "            x : [ batch_size x in_channels x horizon ]\n",
        "            cond : [ batch_size x cond_dim]\n",
        "\n",
        "            returns:\n",
        "            out : [ batch_size x out_channels x horizon ]\n",
        "        '''\n",
        "        out = self.blocks[0](x)\n",
        "        embed = self.cond_encoder(cond)\n",
        "\n",
        "        embed = embed.reshape(\n",
        "            embed.shape[0], 2, self.out_channels, 1)\n",
        "        scale = embed[:,0,...]\n",
        "        bias = embed[:,1,...]\n",
        "        out = scale * out + bias\n",
        "\n",
        "        out = self.blocks[1](out)\n",
        "        out = out + self.residual_conv(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ConditionalUnet1D(nn.Module):\n",
        "    def __init__(self,\n",
        "        input_dim,\n",
        "        global_cond_dim,\n",
        "        diffusion_step_embed_dim=256,\n",
        "        down_dims=[256,512,1024],\n",
        "        kernel_size=5,\n",
        "        n_groups=8\n",
        "        ):\n",
        "        \"\"\"\n",
        "        input_dim: Dim of actions.\n",
        "        global_cond_dim: Dim of global conditioning applied with FiLM\n",
        "          in addition to diffusion step embedding. This is usually obs_horizon * obs_dim\n",
        "        diffusion_step_embed_dim: Size of positional encoding for diffusion iteration k\n",
        "        down_dims: Channel size for each UNet level.\n",
        "          The length of this array determines numebr of levels.\n",
        "        kernel_size: Conv kernel size\n",
        "        n_groups: Number of groups for GroupNorm\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        all_dims = [input_dim] + list(down_dims)\n",
        "        start_dim = down_dims[0]\n",
        "\n",
        "        dsed = diffusion_step_embed_dim\n",
        "        diffusion_step_encoder = nn.Sequential(\n",
        "            SinusoidalPosEmb(dsed),\n",
        "            nn.Linear(dsed, dsed * 4),\n",
        "            nn.Mish(),\n",
        "            nn.Linear(dsed * 4, dsed),\n",
        "        )\n",
        "        cond_dim = dsed + global_cond_dim\n",
        "\n",
        "        in_out = list(zip(all_dims[:-1], all_dims[1:]))\n",
        "        mid_dim = all_dims[-1]\n",
        "        self.mid_modules = nn.ModuleList([\n",
        "            ConditionalResidualBlock1D(\n",
        "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
        "                kernel_size=kernel_size, n_groups=n_groups\n",
        "            ),\n",
        "            ConditionalResidualBlock1D(\n",
        "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
        "                kernel_size=kernel_size, n_groups=n_groups\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "        down_modules = nn.ModuleList([])\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (len(in_out) - 1)\n",
        "            down_modules.append(nn.ModuleList([\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_in, dim_out, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_out, dim_out, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                Downsample1d(dim_out) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        up_modules = nn.ModuleList([])\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
        "            is_last = ind >= (len(in_out) - 1)\n",
        "            up_modules.append(nn.ModuleList([\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_out*2, dim_in, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_in, dim_in, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                Upsample1d(dim_in) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        final_conv = nn.Sequential(\n",
        "            Conv1dBlock(start_dim, start_dim, kernel_size=kernel_size),\n",
        "            nn.Conv1d(start_dim, input_dim, 1),\n",
        "        )\n",
        "\n",
        "        self.diffusion_step_encoder = diffusion_step_encoder\n",
        "        self.up_modules = up_modules\n",
        "        self.down_modules = down_modules\n",
        "        self.final_conv = final_conv\n",
        "\n",
        "        print(\"number of parameters: {:e}\".format(\n",
        "            sum(p.numel() for p in self.parameters()))\n",
        "        )\n",
        "\n",
        "    def forward(self,\n",
        "            sample: torch.Tensor,\n",
        "            timestep: Union[torch.Tensor, float, int],\n",
        "            global_cond=None):\n",
        "        \"\"\"\n",
        "        x: (B,T,input_dim)\n",
        "        timestep: (B,) or int, diffusion step\n",
        "        global_cond: (B,global_cond_dim)\n",
        "        output: (B,T,input_dim)\n",
        "        \"\"\"\n",
        "        # (B,T,C)\n",
        "        sample = sample.moveaxis(-1,-2)\n",
        "        # (B,C,T)\n",
        "\n",
        "        # 1. time\n",
        "        timesteps = timestep\n",
        "        if not torch.is_tensor(timesteps):\n",
        "            # TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\n",
        "            timesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)\n",
        "        elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n",
        "            timesteps = timesteps[None].to(sample.device)\n",
        "        # broadcast to batch dimension in a way that's compatible with ONNX/Core ML\n",
        "        timesteps = timesteps.expand(sample.shape[0])\n",
        "\n",
        "        global_feature = self.diffusion_step_encoder(timesteps)\n",
        "\n",
        "        if global_cond is not None:\n",
        "            global_feature = torch.cat([\n",
        "                global_feature, global_cond\n",
        "            ], axis=-1)\n",
        "\n",
        "        x = sample\n",
        "        h = []\n",
        "        for idx, (resnet, resnet2, downsample) in enumerate(self.down_modules):\n",
        "            x = resnet(x, global_feature)\n",
        "            x = resnet2(x, global_feature)\n",
        "            h.append(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "        for mid_module in self.mid_modules:\n",
        "            x = mid_module(x, global_feature)\n",
        "\n",
        "        for idx, (resnet, resnet2, upsample) in enumerate(self.up_modules):\n",
        "            x = torch.cat((x, h.pop()), dim=1)\n",
        "            x = resnet(x, global_feature)\n",
        "            x = resnet2(x, global_feature)\n",
        "            x = upsample(x)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        # (B,C,T)\n",
        "        x = x.moveaxis(-1,-2)\n",
        "        # (B,T,C)\n",
        "        return x\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "X-XRB_g3vsgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Vision Encoder**\n",
        "#@markdown\n",
        "#@markdown Defines helper functions:\n",
        "#@markdown - `get_resnet` to initialize standard ResNet vision encoder\n",
        "#@markdown - `replace_bn_with_gn` to replace all BatchNorm layers with GroupNorm\n",
        "\n",
        "def get_resnet(name:str, weights=None, **kwargs) -> nn.Module:\n",
        "    \"\"\"\n",
        "    name: resnet18, resnet34, resnet50\n",
        "    weights: \"IMAGENET1K_V1\", None\n",
        "    \"\"\"\n",
        "    # Use standard ResNet implementation from torchvision\n",
        "    func = getattr(torchvision.models, name)\n",
        "    resnet = func(weights=weights, **kwargs)\n",
        "\n",
        "    # remove the final fully connected layer\n",
        "    # for resnet18, the output dim should be 512\n",
        "    resnet.fc = torch.nn.Identity()\n",
        "    return resnet\n",
        "\n",
        "\n",
        "def replace_submodules(\n",
        "        root_module: nn.Module,\n",
        "        predicate: Callable[[nn.Module], bool],\n",
        "        func: Callable[[nn.Module], nn.Module]) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Replace all submodules selected by the predicate with\n",
        "    the output of func.\n",
        "\n",
        "    predicate: Return true if the module is to be replaced.\n",
        "    func: Return new module to use.\n",
        "    \"\"\"\n",
        "    if predicate(root_module):\n",
        "        return func(root_module)\n",
        "\n",
        "    bn_list = [k.split('.') for k, m\n",
        "        in root_module.named_modules(remove_duplicate=True)\n",
        "        if predicate(m)]\n",
        "    for *parent, k in bn_list:\n",
        "        parent_module = root_module\n",
        "        if len(parent) > 0:\n",
        "            parent_module = root_module.get_submodule('.'.join(parent))\n",
        "        if isinstance(parent_module, nn.Sequential):\n",
        "            src_module = parent_module[int(k)]\n",
        "        else:\n",
        "            src_module = getattr(parent_module, k)\n",
        "        tgt_module = func(src_module)\n",
        "        if isinstance(parent_module, nn.Sequential):\n",
        "            parent_module[int(k)] = tgt_module\n",
        "        else:\n",
        "            setattr(parent_module, k, tgt_module)\n",
        "    # verify that all modules are replaced\n",
        "    bn_list = [k.split('.') for k, m\n",
        "        in root_module.named_modules(remove_duplicate=True)\n",
        "        if predicate(m)]\n",
        "    assert len(bn_list) == 0\n",
        "    return root_module\n",
        "\n",
        "def replace_bn_with_gn(\n",
        "    root_module: nn.Module,\n",
        "    features_per_group: int=16) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Relace all BatchNorm layers with GroupNorm.\n",
        "    \"\"\"\n",
        "    replace_submodules(\n",
        "        root_module=root_module,\n",
        "        predicate=lambda x: isinstance(x, nn.BatchNorm2d),\n",
        "        func=lambda x: nn.GroupNorm(\n",
        "            num_groups=x.num_features//features_per_group,\n",
        "            num_channels=x.num_features)\n",
        "    )\n",
        "    return root_module\n"
      ],
      "metadata": {
        "id": "yXq4r744aMh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Network Demo**\n",
        "\n",
        "# construct ResNet18 encoder\n",
        "# if you have multiple camera views, use seperate encoder weights for each view.\n",
        "vision_encoder = get_resnet('resnet18')\n",
        "\n",
        "# IMPORTANT!\n",
        "# replace all BatchNorm with GroupNorm to work with EMA\n",
        "# performance will tank if you forget to do this!\n",
        "vision_encoder = replace_bn_with_gn(vision_encoder)\n",
        "\n",
        "# ResNet18 has output dim of 512\n",
        "vision_feature_dim = 512\n",
        "# agent_pos is 2 dimensional\n",
        "lowdim_obs_dim = 2\n",
        "# observation feature has 514 dims in total per step\n",
        "obs_dim = vision_feature_dim + lowdim_obs_dim\n",
        "action_dim = 2\n",
        "\n",
        "# create network object\n",
        "noise_pred_net = ConditionalUnet1D(\n",
        "    input_dim=action_dim,\n",
        "    global_cond_dim=obs_dim*obs_horizon\n",
        ")\n",
        "\n",
        "# the final arch has 2 parts\n",
        "nets = nn.ModuleDict({\n",
        "    'vision_encoder': vision_encoder,\n",
        "    'noise_pred_net': noise_pred_net\n",
        "})\n",
        "\n",
        "# demo\n",
        "with torch.no_grad():\n",
        "    # example inputs\n",
        "    image = torch.zeros((1, obs_horizon,3,96,96))\n",
        "    agent_pos = torch.zeros((1, obs_horizon, 2))\n",
        "    # vision encoder\n",
        "    image_features = nets['vision_encoder'](\n",
        "        image.flatten(end_dim=1))\n",
        "    # (2,512)\n",
        "    image_features = image_features.reshape(*image.shape[:2],-1)\n",
        "    # (1,2,512)\n",
        "    obs = torch.cat([image_features, agent_pos],dim=-1)\n",
        "    # (1,2,514)\n",
        "\n",
        "    noised_action = torch.randn((1, pred_horizon, action_dim))\n",
        "    diffusion_iter = torch.zeros((1,))\n",
        "\n",
        "    # the noise prediction network\n",
        "    # takes noisy action, diffusion iteration and observation as input\n",
        "    # predicts the noise added to action\n",
        "    noise = nets['noise_pred_net'](\n",
        "        sample=noised_action,\n",
        "        timestep=diffusion_iter,\n",
        "        global_cond=obs.flatten(start_dim=1))\n",
        "\n",
        "    # illustration of removing noise\n",
        "    # the actual noise removal is performed by NoiseScheduler\n",
        "    # and is dependent on the diffusion noise schedule\n",
        "    denoised_action = noised_action - noise\n",
        "\n",
        "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
        "num_diffusion_iters = 100\n",
        "noise_scheduler = DDPMScheduler(\n",
        "    num_train_timesteps=num_diffusion_iters,\n",
        "    # the choise of beta schedule has big impact on performance\n",
        "    # we found squared cosine works the best\n",
        "    beta_schedule='squaredcos_cap_v2',\n",
        "    # clip output to [-1,1] to improve stability\n",
        "    clip_sample=True,\n",
        "    # our network predicts noise (instead of denoised action)\n",
        "    prediction_type='epsilon'\n",
        ")\n",
        "\n",
        "# device transfer\n",
        "device = torch.device('cuda')\n",
        "_ = nets.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4APZkqh336-M",
        "outputId": "9343e243-cd8b-4c1b-de51-4f1c78aa2391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 7.994727e+07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Training**\n",
        "#@markdown\n",
        "#@markdown Takes about 2.5 hours. If you don't want to wait, skip to the next cell\n",
        "#@markdown to load pre-trained weights\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "# Exponential Moving Average\n",
        "# accelerates training and improves stability\n",
        "# holds a copy of the model weights\n",
        "ema = EMAModel(\n",
        "    parameters=nets.parameters(),\n",
        "    power=0.75)\n",
        "\n",
        "# Standard ADAM optimizer\n",
        "# Note that EMA parametesr are not optimized\n",
        "optimizer = torch.optim.AdamW(\n",
        "    params=nets.parameters(),\n",
        "    lr=1e-4, weight_decay=1e-6)\n",
        "\n",
        "# Cosine LR schedule with linear warmup\n",
        "lr_scheduler = get_scheduler(\n",
        "    name='cosine',\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=500,\n",
        "    num_training_steps=len(dataloader) * num_epochs\n",
        ")\n",
        "\n",
        "with tqdm(range(num_epochs), desc='Epoch') as tglobal:\n",
        "    # epoch loop\n",
        "    for epoch_idx in tglobal:\n",
        "        epoch_loss = list()\n",
        "        # batch loop\n",
        "        with tqdm(dataloader, desc='Batch', leave=False) as tepoch:\n",
        "            for nbatch in tepoch:\n",
        "                # data normalized in dataset\n",
        "                # device transfer\n",
        "                nimage = nbatch['image'][:,:obs_horizon].to(device)\n",
        "                nagent_pos = nbatch['agent_pos'][:,:obs_horizon].to(device)\n",
        "                naction = nbatch['action'].to(device)\n",
        "                B = nagent_pos.shape[0]\n",
        "\n",
        "                # encoder vision features\n",
        "                image_features = nets['vision_encoder'](\n",
        "                    nimage.flatten(end_dim=1))\n",
        "                image_features = image_features.reshape(\n",
        "                    *nimage.shape[:2],-1)\n",
        "                # (B,obs_horizon,D)\n",
        "\n",
        "                # concatenate vision feature and low-dim obs\n",
        "                obs_features = torch.cat([image_features, nagent_pos], dim=-1)\n",
        "                obs_cond = obs_features.flatten(start_dim=1)\n",
        "                # (B, obs_horizon * obs_dim)\n",
        "\n",
        "                # sample noise to add to actions\n",
        "                noise = torch.randn(naction.shape, device=device)\n",
        "\n",
        "                # sample a diffusion iteration for each data point\n",
        "                timesteps = torch.randint(\n",
        "                    0, noise_scheduler.config.num_train_timesteps,\n",
        "                    (B,), device=device\n",
        "                ).long()\n",
        "\n",
        "                # add noise to the clean images according to the noise magnitude at each diffusion iteration\n",
        "                # (this is the forward diffusion process)\n",
        "                noisy_actions = noise_scheduler.add_noise(\n",
        "                    naction, noise, timesteps)\n",
        "\n",
        "                # predict the noise residual\n",
        "                noise_pred = noise_pred_net(\n",
        "                    noisy_actions, timesteps, global_cond=obs_cond)\n",
        "\n",
        "                # L2 loss\n",
        "                loss = nn.functional.mse_loss(noise_pred, noise)\n",
        "\n",
        "                # optimize\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                # step lr scheduler every batch\n",
        "                # this is different from standard pytorch behavior\n",
        "                lr_scheduler.step()\n",
        "\n",
        "                # update Exponential Moving Average of the model weights\n",
        "                ema.step(nets.parameters())\n",
        "\n",
        "                # logging\n",
        "                loss_cpu = loss.item()\n",
        "                epoch_loss.append(loss_cpu)\n",
        "                tepoch.set_postfix(loss=loss_cpu)\n",
        "        tglobal.set_postfix(loss=np.mean(epoch_loss))\n",
        "\n",
        "# Weights of the EMA model\n",
        "# is used for inference\n",
        "ema_nets = nets\n",
        "ema.copy_to(ema_nets.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "17495902022d4ad5b24cad740cf9c1e4",
            "7586ebd7358d48cdbbee37593797804e",
            "6c9f8c7f692f45318ad29bcb65cd6344",
            "fdd0f37e33f742d4b790b0d64697fe83",
            "8888d54e6f454a68bc26b45e7824f6e7",
            "5e7d0314724e43c48ab494edd105eb4d",
            "41d3a0c27922408b87d5b6599a4281fb",
            "3587c826181f4578b9df3c5ba7425a3b",
            "7975925b464d4c6b8f78837da82a2c8f",
            "f82530285508473aaa7e0b48c8c26792",
            "967069f2a7fc4b419d9ed15e787bd3ea",
            "af12ac7fcc71474ca44d11f27f3023c9",
            "195a12c694594acc89e4840a44574087",
            "95cf8565184e4601948ea7ef142bda96",
            "abed40b66be14ab198ee304940bc438f",
            "3776e3970e244e518d365cdde07358fc",
            "704ae26d31cc43d483d5459fad17778b",
            "702901ec086240bcaf88e4c62939357a",
            "30f2aa65d71844fab3371983c6c9f420",
            "d057f930be1240129112568a4d0b0be3",
            "88df1f95725048f8ad5b8366a7dd0055",
            "8b0a31db42b94bdda58762dbb4b1d841"
          ]
        },
        "id": "93E9RdnR4D8v",
        "outputId": "958d1666-a989-4e99-8fc5-a4048921692e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17495902022d4ad5b24cad740cf9c1e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batch:   0%|          | 0/379 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af12ac7fcc71474ca44d11f27f3023c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f4a4300adba5>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;31m# optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Loading Pretrained Checkpoint**\n",
        "#@markdown Set `load_pretrained = True` to load pretrained weights.\n",
        "\n",
        "load_pretrained = True\n",
        "if load_pretrained:\n",
        "  ckpt_path = \"pusht_vision_100ep.ckpt\"\n",
        "  if not os.path.isfile(ckpt_path):\n",
        "      id = \"1XKpfNSlwYMGaF5CncoFaLKCDTWoLAHf1&confirm=t\"\n",
        "      gdown.download(id=id, output=ckpt_path, quiet=False)\n",
        "\n",
        "  state_dict = torch.load(ckpt_path, map_location='cuda')\n",
        "  ema_nets = nets\n",
        "  ema_nets.load_state_dict(state_dict)\n",
        "  print('Pretrained weights loaded.')\n",
        "else:\n",
        "  print(\"Skipped pretrained weight loading.\")"
      ],
      "metadata": {
        "id": "6F3hUbIuxGdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1072c9ed-aa44-4d94-b9de-4699eb07eb61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XKpfNSlwYMGaF5CncoFaLKCDTWoLAHf1&confirm=t\n",
            "To: /content/pusht_vision_100ep.ckpt\n",
            "100%|██████████| 365M/365M [00:13<00:00, 27.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained weights loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Inference**\n",
        "\n",
        "# limit enviornment interaction to 200 steps before termination\n",
        "max_steps = 200\n",
        "env = PushTImageEnv()\n",
        "# use a seed >200 to avoid initial states seen in the training dataset\n",
        "env.seed(100000)\n",
        "\n",
        "# get first observation\n",
        "obs, info = env.reset()\n",
        "\n",
        "# keep a queue of last 2 steps of observations\n",
        "obs_deque = collections.deque(\n",
        "    [obs] * obs_horizon, maxlen=obs_horizon)\n",
        "# save visualization and rewards\n",
        "imgs = [env.render(mode='rgb_array')]\n",
        "rewards = list()\n",
        "done = False\n",
        "step_idx = 0\n",
        "\n",
        "with tqdm(total=max_steps, desc=\"Eval PushTImageEnv\") as pbar:\n",
        "    while not done:\n",
        "        B = 1\n",
        "        # stack the last obs_horizon number of observations\n",
        "        images = np.stack([x['image'] for x in obs_deque])\n",
        "        agent_poses = np.stack([x['agent_pos'] for x in obs_deque])\n",
        "\n",
        "        # normalize observation\n",
        "        nagent_poses = normalize_data(agent_poses, stats=stats['agent_pos'])\n",
        "        # images are already normalized to [0,1]\n",
        "        nimages = images\n",
        "\n",
        "        # device transfer\n",
        "        nimages = torch.from_numpy(nimages).to(device, dtype=torch.float32)\n",
        "        # (2,3,96,96)\n",
        "        nagent_poses = torch.from_numpy(nagent_poses).to(device, dtype=torch.float32)\n",
        "        # (2,2)\n",
        "\n",
        "        # infer action\n",
        "        with torch.no_grad():\n",
        "            # get image features\n",
        "            image_features = ema_nets['vision_encoder'](nimages)\n",
        "            # (2,512)\n",
        "\n",
        "            # concat with low-dim observations\n",
        "            obs_features = torch.cat([image_features, nagent_poses], dim=-1)\n",
        "\n",
        "            # reshape observation to (B,obs_horizon*obs_dim)\n",
        "            obs_cond = obs_features.unsqueeze(0).flatten(start_dim=1)\n",
        "\n",
        "            # initialize action from Guassian noise\n",
        "            noisy_action = torch.randn(\n",
        "                (B, pred_horizon, action_dim), device=device)\n",
        "            naction = noisy_action\n",
        "\n",
        "            # init scheduler\n",
        "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
        "\n",
        "            for k in noise_scheduler.timesteps:\n",
        "                # predict noise\n",
        "                noise_pred = ema_nets['noise_pred_net'](\n",
        "                    sample=naction,\n",
        "                    timestep=k,\n",
        "                    global_cond=obs_cond\n",
        "                )\n",
        "\n",
        "                # inverse diffusion step (remove noise)\n",
        "                naction = noise_scheduler.step(\n",
        "                    model_output=noise_pred,\n",
        "                    timestep=k,\n",
        "                    sample=naction\n",
        "                ).prev_sample\n",
        "\n",
        "        # unnormalize action\n",
        "        naction = naction.detach().to('cpu').numpy()\n",
        "        # (B, pred_horizon, action_dim)\n",
        "        naction = naction[0]\n",
        "        action_pred = unnormalize_data(naction, stats=stats['action'])\n",
        "\n",
        "        # only take action_horizon number of actions\n",
        "        start = obs_horizon - 1\n",
        "        end = start + action_horizon\n",
        "        action = action_pred[start:end,:]\n",
        "        # (action_horizon, action_dim)\n",
        "\n",
        "        # execute action_horizon number of steps\n",
        "        # without replanning\n",
        "        for i in range(len(action)):\n",
        "            # stepping env\n",
        "            obs, reward, done, _, info = env.step(action[i])\n",
        "            # save observations\n",
        "            obs_deque.append(obs)\n",
        "            # and reward/vis\n",
        "            rewards.append(reward)\n",
        "            imgs.append(env.render(mode='rgb_array'))\n",
        "\n",
        "            # update progress bar\n",
        "            step_idx += 1\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix(reward=reward)\n",
        "            if step_idx > max_steps:\n",
        "                done = True\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "# print out the maximum target coverage\n",
        "print('Score: ', max(rewards))\n",
        "\n",
        "# visualize\n",
        "from IPython.display import Video\n",
        "vwrite('vis.mp4', imgs)\n",
        "Video('vis.mp4', embed=True, width=256, height=256)"
      ],
      "metadata": {
        "id": "OyLjlNQk5nr9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326,
          "referenced_widgets": [
            "f38f444596eb4d30970dc3b7b623feae",
            "95025eff74fc41bba34c06ead454c179",
            "995fc6fe002b427f953dc4f6bbe3b76e",
            "65b24fe04a444e4185e6cd24b03b4ff9",
            "a776f50ea9df4e2bb5e311ab6b9028df",
            "71fff78494694f4f9b4565e74362c116",
            "2be82f21ebf54be4bde9a0d5d64e100f",
            "6781cbfdcd1f45bb8f7e016395ebcde1",
            "d25fb1f7c0ae4c7d95ba796febfe6873",
            "b70250a5da924ca2b5a54b9c177c3082",
            "d5e6cb2573454c94964b8d7caa5a229d"
          ]
        },
        "outputId": "ca0b125d-7905-4726-ed05-4057d83cd42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval PushTImageEnv:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f38f444596eb4d30970dc3b7b623feae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score:  0.9852001494386361\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls  width=\"256\"  height=\"256\">\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}